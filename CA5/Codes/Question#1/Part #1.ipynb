{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Mushroom_Train.csv')\n",
    "df_test = pd.read_csv('Mushroom_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train.drop(['class'], axis = 1)\n",
    "y_train=df_train['class']\n",
    "X_test=df_test.drop(['class'], axis = 1)\n",
    "y_test=df_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDict = {}\n",
    "count=0\n",
    "for col_name in X_train.columns: \n",
    "    featureDict[count]= np.unique(X_train[col_name])\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion(actual, predicted):\n",
    "\n",
    "    \n",
    "    classes = np.unique(actual)\n",
    "    confusion_matrix = np.zeros((len(classes), len(classes)))\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            confusion_matrix[i, j] = np.sum((actual == classes[i]) & (predicted == classes[j]))\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prior_Probability_Calculator(df_train):\n",
    "    target=df_train[\"class\"]\n",
    "    e_count=sum(target == 'e')\n",
    "    p_count=sum(target == 'p')\n",
    "    return e_count/target.size,p_count/target.size   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Likelihood_Probability_Calculator(X_train,y_train):\n",
    "    \n",
    "    \n",
    "    e_count=sum(y_train == 'e')\n",
    "    p_count=sum(y_train == 'p')\n",
    "    \n",
    "    train_e = X_train[y_train=='e']\n",
    "    train_p = X_train[y_train=='p']\n",
    "    \n",
    "\n",
    "    dictionary_probE = {}\n",
    "    dictionary_probP = {}\n",
    "    cnt=0\n",
    "    for col_name in train_e.columns: \n",
    "\n",
    "        e_unique, e_counts = np.unique(train_e[col_name],return_counts=True)\n",
    "        p_unique, p_counts = np.unique(train_p[col_name],return_counts=True)\n",
    "        e_countDict = dict(zip(e_unique,e_counts))\n",
    "        p_countDict = dict(zip(p_unique,p_counts))\n",
    "        prob_e = {}\n",
    "        prob_p = {}\n",
    "        for st in featureDict[cnt]:\n",
    "            if st in e_countDict:\n",
    "                prob_e[st]=float(e_countDict[st]/e_count)\n",
    "            else:\n",
    "                prob_e[st]=float(0)\n",
    "                \n",
    "            if st in p_countDict:\n",
    "                prob_p[st]=float(p_countDict[st]/p_count)\n",
    "            else:\n",
    "                prob_p[st]=float(0)\n",
    "               \n",
    "      \n",
    "               \n",
    "        dictionary_probE[cnt]=prob_e\n",
    "        dictionary_probP[cnt]=prob_p\n",
    "        cnt=cnt+1\n",
    "    return dictionary_probE,dictionary_probP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test,e_prior,p_prior):\n",
    "    \n",
    "    \n",
    "    length,d=np.shape(X_test)\n",
    "    \n",
    "    stored_data = np.zeros((length,2), dtype=float)\n",
    "\n",
    "    \n",
    "    cnt2=0\n",
    "    for idx,row in X_test.iterrows():\n",
    "        eProb=e_prior\n",
    "        pProb=p_prior\n",
    "        for j in range(0,d):\n",
    "            \n",
    "            featuree=row[j]\n",
    "            if featuree !='?' :\n",
    "                eProb = eProb * dictionary_probE[j][featuree]\n",
    "                pProb = pProb * dictionary_probP[j][featuree]\n",
    "        stored_data[cnt2][0]=eProb\n",
    "        stored_data[cnt2][1]=pProb\n",
    "        cnt2=cnt2+1\n",
    "        \n",
    "    predicted = np.zeros((length), dtype='str')\n",
    "    for i in range(0,length):\n",
    "        if np.argmax(stored_data[i]) == 0:\n",
    "            predicted[i]='e'\n",
    "        else:\n",
    "            predicted[i]='p'\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percent is:\n",
      "% 99.23664122137404\n"
     ]
    }
   ],
   "source": [
    "e_prior,p_prior=Prior_Probability_Calculator(df_train)\n",
    "dictionary_probE,dictionary_probP=Likelihood_Probability_Calculator(X_train,y_train)\n",
    "y_test_pred=predict(X_test,e_prior,p_prior)\n",
    "L,dd=np.shape(X_test)\n",
    "\n",
    "print (\"Accuracy percent is:\")\n",
    "print (\"%\",(y_test_pred==y_test).sum()*100/L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix is:\n",
      "\n",
      "[[245   4]\n",
      " [  0 275]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix=calculate_confusion(y_test,y_test_pred)\n",
    "\n",
    "print(\"confusion Matrix is:\\n\")\n",
    "print(confusion_matrix.astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
